{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação das Bibliotecas Necessárias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importação de Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score,\n",
    "    roc_curve\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divisão dos Dados em Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividindo os dados em conjunto de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instanciando o modelo\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Treinando o modelo\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avaliação do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo Previsões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a acurácia\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise dos Resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatório de Classificação\n",
    "\n",
    "Interpretação:\n",
    "\n",
    "Precision (Precisão): Proporção de previsões positivas corretas em relação ao total de previsões positivas feitas pelo modelo.\n",
    "Recall (Sensibilidade): Proporção de casos positivos corretos identificados pelo modelo em relação ao total de casos positivos reais.\n",
    "F1-Score: Média harmônica entre precisão e recall. É uma métrica balanceada para avaliar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibindo o relatório de classificação\n",
    "print(\"Relatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matriz de Confusão\n",
    "\n",
    "Interpretação:\n",
    "\n",
    "Verdadeiros Positivos (TP): Casos em que o modelo previu \"Default\" e o cliente realmente não pagou.\n",
    "Verdadeiros Negativos (TN): Casos em que o modelo previu \"Reembolso\" e o cliente realmente pagou.\n",
    "Falsos Positivos (FP): Casos em que o modelo previu \"Default\" mas o cliente pagou.\n",
    "Falsos Negativos (FN): Casos em que o modelo previu \"Reembolso\" mas o cliente não pagou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a matriz de confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plotando a matriz de confusão\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Reembolso', 'Default'], yticklabels=['Reembolso', 'Default'])\n",
    "plt.ylabel('Valor Real')\n",
    "plt.xlabel('Previsão do Modelo')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curva ROC e AUC\n",
    "\n",
    "Interpretação:\n",
    "\n",
    "Curva ROC: Mostra a relação entre a taxa de verdadeiros positivos (sensibilidade) e a taxa de falsos positivos para diferentes limiares.\n",
    "AUC (Area Under the Curve): Mede a capacidade do modelo em classificar corretamente as classes. Valores próximos a 1 indicam um modelo com bom desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Probabilidades de predição para a classe positiva\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# Calculando a Curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Calculando a AUC\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Plotando a Curva ROC\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Curva ROC (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0,1], [0,1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('Taxa de Falso Positivo')\n",
    "plt.ylabel('Taxa de Verdadeiro Positivo')\n",
    "plt.title('Curva ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise dos Coeficientes do Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importância das Variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo os coeficientes do modelo\n",
    "coefficients = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Coefficient': model.coef_[0]\n",
    "})\n",
    "\n",
    "# Calculando o valor absoluto dos coeficientes\n",
    "coefficients['Abs_Coefficient'] = coefficients['Coefficient'].abs()\n",
    "\n",
    "# Ordenando as variáveis pela importância\n",
    "coefficients = coefficients.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Visualizando as 10 variáveis mais importantes\n",
    "print(\"Coeficientes das Variáveis:\")\n",
    "print(coefficients[['Feature', 'Coefficient']].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotando a Importância das Variáveis\n",
    "\n",
    "Interpretação:\n",
    "\n",
    "Os coeficientes positivos indicam que um aumento na variável está associado a um aumento na probabilidade de default.\n",
    "Os coeficientes negativos indicam que um aumento na variável está associado a uma diminuição na probabilidade de default.\n",
    "As variáveis com coeficientes de maior magnitude (positiva ou negativa) têm maior impacto nas previsões do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando os coeficientes\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=coefficients.head(10))\n",
    "plt.title('Importância das Variáveis (Top 10)')\n",
    "plt.xlabel('Coeficiente')\n",
    "plt.ylabel('Variável')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identificação dos Fatores de Risco\n",
    "Com base nos coeficientes do modelo, podemos identificar quais variáveis contribuem mais para o risco de crédito.\n",
    "\n",
    "Análise dos Principais Fatores:\n",
    "Taxa de Juros do Empréstimo (loan_int_rate):\n",
    "\n",
    "Coeficiente positivo: Taxas de juros mais altas estão associadas a um maior risco de default.\n",
    "Interpretação: Clientes com taxas de juros mais altas podem ter maior dificuldade em pagar o empréstimo.\n",
    "Percentual da Renda Comprometida com o Empréstimo (loan_percent_income):\n",
    "\n",
    "Coeficiente positivo: Quanto maior o percentual da renda comprometida, maior o risco.\n",
    "Interpretação: Clientes que comprometem uma grande parte de sua renda com o empréstimo têm maior probabilidade de inadimplência.\n",
    "Histórico de Crédito (cb_person_cred_hist_length):\n",
    "\n",
    "Coeficiente negativo: Um histórico de crédito mais longo está associado a um menor risco.\n",
    "Interpretação: Clientes com um histórico de crédito mais longo geralmente têm mais experiência em lidar com crédito e podem ser considerados menos arriscados.\n",
    "Intenção do Empréstimo (loan_intent):\n",
    "\n",
    "Variáveis dummy indicando o propósito do empréstimo (e.g., loan_intent_DEBTCONSOLIDATION).\n",
    "Certas intenções podem estar associadas a maiores riscos.\n",
    "Nota de Crédito (loan_grade):\n",
    "\n",
    "Variáveis dummy para diferentes categorias de nota de crédito.\n",
    "Notas mais baixas (e.g., loan_grade_G) estão associadas a maior risco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualização da Distribuição das Variáveis\n",
    "Podemos explorar a distribuição das variáveis mais importantes e como elas diferem entre os clientes que pagaram e os que não pagaram o empréstimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribuição da Taxa de Juros por Status do Empréstimo\n",
    "\n",
    "Interpretação:\n",
    "\n",
    "Clientes que não pagaram tendem a ter taxas de juros mais altas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='loan_status', y='loan_int_rate', data=df_gold)\n",
    "plt.title('Distribuição da Taxa de Juros por Status do Empréstimo')\n",
    "plt.xlabel('Status do Empréstimo (0 = Pagou, 1 = Default)')\n",
    "plt.ylabel('Taxa de Juros (%)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribuição do Percentual de Renda Comprometida\n",
    "\n",
    "Interpretação:\n",
    "\n",
    "Clientes inadimplentes geralmente comprometem uma parcela maior de sua renda com o empréstimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.boxplot(x='loan_status', y='loan_percent_income', data=df_gold)\n",
    "plt.title('Percentual de Renda Comprometida por Status do Empréstimo')\n",
    "plt.xlabel('Status do Empréstimo (0 = Pagou, 1 = Default)')\n",
    "plt.ylabel('Percentual de Renda Comprometida')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusões e Insights\n",
    "Desempenho do Modelo:\n",
    "\n",
    "Acurácia: O modelo possui uma acurácia de aproximadamente X% (substitua pelo valor real obtido).\n",
    "AUC: A área sob a curva ROC é de Y (substitua pelo valor real), indicando que o modelo tem um bom poder discriminativo.\n",
    "Principais Fatores de Risco:\n",
    "\n",
    "Taxa de Juros Elevada: Clientes com taxas de juros mais altas têm maior risco de default.\n",
    "Alto Comprometimento da Renda: Um alto percentual da renda comprometida com o empréstimo aumenta o risco.\n",
    "Curto Histórico de Crédito: Clientes com um histórico de crédito mais curto estão associados a um risco maior.\n",
    "Intenção do Empréstimo: Certos propósitos do empréstimo, como consolidação de dívidas, podem estar associados a maiores riscos.\n",
    "Recomendações:\n",
    "\n",
    "Avaliação Rigorosa: Realizar uma análise mais detalhada para clientes com taxas de juros altas e alto comprometimento de renda.\n",
    "Políticas de Crédito: Revisar as políticas para aprovar empréstimos com base nos fatores de risco identificados.\n",
    "Educação Financeira: Oferecer programas de educação financeira para clientes com histórico de crédito curto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definição do Diretório Base e Criação das Pastas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Diretório base para as camadas do ETL\n",
    "base_dir = '/home/savidotti/programmers/credit-risk-analysis/pipeline_etl/etl_camadas'\n",
    "\n",
    "# Função para criar o diretório se não existir\n",
    "def create_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada Bronze: Carregamento dos Dados Brutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados da Camada Bronze:\n",
      "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
      "0          22          59000                  RENT              123.0   \n",
      "1          21           9600                   OWN                5.0   \n",
      "2          25           9600              MORTGAGE                1.0   \n",
      "3          23          65500                  RENT                4.0   \n",
      "4          24          54400                  RENT                8.0   \n",
      "\n",
      "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
      "0    PERSONAL          D      35000          16.02            1   \n",
      "1   EDUCATION          B       1000          11.14            0   \n",
      "2     MEDICAL          C       5500          12.87            1   \n",
      "3     MEDICAL          C      35000          15.23            1   \n",
      "4     MEDICAL          C      35000          14.27            1   \n",
      "\n",
      "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
      "0                 0.59                         Y                           3  \n",
      "1                 0.10                         N                           2  \n",
      "2                 0.57                         N                           3  \n",
      "3                 0.53                         N                           2  \n",
      "4                 0.55                         Y                           4  \n"
     ]
    }
   ],
   "source": [
    "# Caminho para o arquivo CSV original\n",
    "raw_data_path = '/home/savidotti/programmers/credit-risk-analysis/dataset/credit_risk_dataset.csv'\n",
    "\n",
    "# Carregando os dados brutos\n",
    "df_bronze = pd.read_csv(raw_data_path)\n",
    "\n",
    "# Visualizando as primeiras linhas do DataFrame\n",
    "print(\"Dados da Camada Bronze:\")\n",
    "print(df_bronze.head())\n",
    "\n",
    "# Criando o diretório para a camada bronze\n",
    "bronze_dir = os.path.join(base_dir, 'bronze')\n",
    "create_dir(bronze_dir)\n",
    "\n",
    "# Salvando o DataFrame da camada bronze em formato CSV\n",
    "bronze_file_path = os.path.join(bronze_dir, 'credit_risk_bronze.csv')\n",
    "df_bronze.to_csv(bronze_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada Silver: Limpeza e Transformação Básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Valores ausentes antes do tratamento:\n",
      "person_age                       0\n",
      "person_income                    0\n",
      "person_home_ownership            0\n",
      "person_emp_length              895\n",
      "loan_intent                      0\n",
      "loan_grade                       0\n",
      "loan_amnt                        0\n",
      "loan_int_rate                 3116\n",
      "loan_status                      0\n",
      "loan_percent_income              0\n",
      "cb_person_default_on_file        0\n",
      "cb_person_cred_hist_length       0\n",
      "dtype: int64\n",
      "\n",
      "Valores ausentes após o tratamento:\n",
      "person_age                       0\n",
      "person_income                    0\n",
      "person_home_ownership            0\n",
      "person_emp_length                0\n",
      "loan_intent                      0\n",
      "loan_grade                       0\n",
      "loan_amnt                        0\n",
      "loan_int_rate                 3116\n",
      "loan_status                      0\n",
      "loan_percent_income              0\n",
      "cb_person_default_on_file        0\n",
      "cb_person_cred_hist_length       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Criando uma cópia dos dados brutos\n",
    "df_silver = df_bronze.copy()\n",
    "\n",
    "# Verificando valores ausentes\n",
    "print(\"\\nValores ausentes antes do tratamento:\")\n",
    "print(df_silver.isnull().sum())\n",
    "\n",
    "# Tratamento de valores ausentes (se houver)\n",
    "if df_silver['person_emp_length'].isnull().sum() > 0:\n",
    "    df_silver['person_emp_length'].fillna(df_silver['person_emp_length'].median(), inplace=True)\n",
    "\n",
    "# Convertendo tipos de dados\n",
    "df_silver['person_age'] = df_silver['person_age'].astype(int)\n",
    "df_silver['person_income'] = df_silver['person_income'].astype(float)\n",
    "df_silver['loan_amnt'] = df_silver['loan_amnt'].astype(float)\n",
    "df_silver['loan_int_rate'] = df_silver['loan_int_rate'].astype(float)\n",
    "df_silver['loan_status'] = df_silver['loan_status'].astype(int)\n",
    "df_silver['loan_percent_income'] = df_silver['loan_percent_income'].astype(float)\n",
    "df_silver['cb_person_cred_hist_length'] = df_silver['cb_person_cred_hist_length'].astype(int)\n",
    "\n",
    "# Verificando valores ausentes após o tratamento\n",
    "print(\"\\nValores ausentes após o tratamento:\")\n",
    "print(df_silver.isnull().sum())\n",
    "\n",
    "# Criando o diretório para a camada silver\n",
    "silver_dir = os.path.join(base_dir, 'silver')\n",
    "create_dir(silver_dir)\n",
    "\n",
    "# Salvando o DataFrame da camada silver em formato Parquet\n",
    "silver_file_path = os.path.join(silver_dir, 'credit_risk_silver.parquet')\n",
    "df_silver.to_parquet(silver_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Camada Gold: Enriquecimento e Preparação para ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Criando uma cópia dos dados da camada silver\n",
    "df_gold = df_silver.copy()\n",
    "\n",
    "# Engenharia de Características\n",
    "\n",
    "# Criar uma variável binária para indicar se a pessoa possui casa própria\n",
    "df_gold['is_home_owner'] = df_gold['person_home_ownership'].apply(lambda x: 1 if x in ['OWN', 'MORTGAGE'] else 0)\n",
    "\n",
    "# Tratamento de valores nulos em 'person_home_ownership' (se houver)\n",
    "if df_gold['person_home_ownership'].isnull().sum() > 0:\n",
    "    df_gold['person_home_ownership'].fillna('OTHER', inplace=True)\n",
    "\n",
    "# Codificação de variáveis categóricas\n",
    "categorical_vars = ['loan_intent', 'loan_grade', 'cb_person_default_on_file']\n",
    "\n",
    "# Usando one-hot encoding para variáveis categóricas\n",
    "df_gold = pd.get_dummies(df_gold, columns=categorical_vars, drop_first=True)\n",
    "\n",
    "# Atualizando a lista de features com as novas colunas criadas\n",
    "features = [\n",
    "    'person_age',\n",
    "    'person_income',\n",
    "    'person_emp_length',\n",
    "    'loan_amnt',\n",
    "    'loan_int_rate',\n",
    "    'loan_percent_income',\n",
    "    'cb_person_cred_hist_length',\n",
    "    'is_home_owner'\n",
    "]\n",
    "\n",
    "# Adicionando as colunas de variáveis dummies\n",
    "features += [\n",
    "    col for col in df_gold.columns \n",
    "    if col.startswith('loan_intent_') \n",
    "    or col.startswith('loan_grade_') \n",
    "    or col.startswith('cb_person_default_on_file_')\n",
    "]\n",
    "\n",
    "# Definindo as variáveis X e y\n",
    "X = df_gold[features]\n",
    "y = df_gold['loan_status']\n",
    "\n",
    "# Criando o diretório para a camada gold\n",
    "gold_dir = os.path.join(base_dir, 'gold')\n",
    "create_dir(gold_dir)\n",
    "\n",
    "# Salvando o DataFrame da camada gold em formato Parquet\n",
    "gold_file_path = os.path.join(gold_dir, 'credit_risk_gold.parquet')\n",
    "df_gold.to_parquet(gold_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
